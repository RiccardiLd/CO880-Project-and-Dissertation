{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-slave",
   "metadata": {},
   "source": [
    "# Insurance Pricing with XGBoost\n",
    "**Submitted as part of the Corpus of CO880: Project and Dissertation**\n",
    "\n",
    "*gr305 - Gianni Riccardi*\n",
    "\n",
    "This notebook is part of a series of interactive python notebooks that are used to test many different approaches to insurance price prediction with machine learning techniques.\n",
    "\n",
    "In this notebook, we attempt to use XGBoost to predict the number of claims made by a policyholder. With this information and the readly available exposure of the policyholder, we can predict the frequency of claims for any given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "printable-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_poisson_deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-montgomery",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We will use the [French Motor Third-Party Liability Claims](https://www.openml.org/d/41214) dataset. This dataset has been studied in detail by A. Noll, R. Salzmann and M.V. Wuthrich, in their 2018 paper [Case Study: French Motor Third-Party Liability Claims](doi:10.2139/ssrn.3164764). \n",
    "\n",
    "Many assumptions and decisions made during the tests below were driven by this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weekly-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimNb</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Area</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>VehBrand</th>\n",
       "      <th>VehGas</th>\n",
       "      <th>Density</th>\n",
       "      <th>Region</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>R82</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>R82</td>\n",
       "      <td>1.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>54.0</td>\n",
       "      <td>R22</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>B</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>76.0</td>\n",
       "      <td>R72</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>B</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>76.0</td>\n",
       "      <td>R72</td>\n",
       "      <td>1.190476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand  \\\n",
       "0      1.0      0.10    D       5.0     0.0     55.0        50.0      B12   \n",
       "1      1.0      0.77    D       5.0     0.0     55.0        50.0      B12   \n",
       "2      1.0      0.75    B       6.0     2.0     52.0        50.0      B12   \n",
       "3      1.0      0.09    B       7.0     0.0     46.0        50.0      B12   \n",
       "4      1.0      0.84    B       7.0     0.0     46.0        50.0      B12   \n",
       "\n",
       "    VehGas  Density Region  Frequency  \n",
       "0  Regular   1217.0    R82  10.000000  \n",
       "1  Regular   1217.0    R82   1.298701  \n",
       "2   Diesel     54.0    R22   1.333333  \n",
       "3   Diesel     76.0    R72  11.111111  \n",
       "4   Diesel     76.0    R72   1.190476  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "raw_df = fetch_openml(data_id=41214, as_frame=True).frame\n",
    "\n",
    "df = raw_df.copy().drop(columns=['IDpol'])\n",
    "df[\"Frequency\"] = df[\"ClaimNb\"] / df[\"Exposure\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-jacket",
   "metadata": {},
   "source": [
    "### Cleaning up the data\n",
    "\n",
    "We need to clean the data before feeding it to the Boosted Tree. In the following steps, we use SKLearn's label encoder to properly encode the columns \"Area\", \"VehBrand\", \"VehGas\" and \"Region\" into something that the Tree can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valuable-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (474609,)\n",
      "Training features shape: (474609, 9)\n",
      "Validation labels shape: (203404,)\n",
      "Validation features shape: (203404, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "# split data into X and y\n",
    "X = df.drop(columns=['ClaimNb', 'Exposure', 'Frequency'])\n",
    "Y = lbl.fit_transform(df['Frequency'].astype(str))\n",
    "\n",
    "X['Area'] = lbl.fit_transform(X['Area'].astype(str))\n",
    "X['VehBrand'] = lbl.fit_transform(X['VehBrand'].astype(str))\n",
    "X['VehGas'] = lbl.fit_transform(X['VehGas'].astype(str))\n",
    "X['Region'] = lbl.fit_transform(X['Region'].astype(str))\n",
    "\n",
    "seed = 10\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation labels shape:', y_test.shape)\n",
    "print('Validation features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-arkansas",
   "metadata": {},
   "source": [
    "We can now create our XGB Classifier model to predict frequency of claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jewish-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    seed=0, \n",
    "    eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "military-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, seed=0,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "political-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exclusive-brook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.092112249513284 MSE: 520.3244577294448 accuracy: 0.9495585140901851\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "#mpd = mean_poisson_deviance(y_test, predictions)\n",
    "\n",
    "print(\"MAE:\", mae, \"MSE:\", mse, \"accuracy:\", (y_test == y_pred).sum()/float(y_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-reconstruction",
   "metadata": {},
   "source": [
    "The model has a very high accuracy, but is suffering from the class imbalance problem (discussed in more detail in the notebook \"French Motor Claims - DNN - SMOTE\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-offset",
   "metadata": {},
   "source": [
    "## Comparison with the DNN\n",
    "\n",
    "The test below is made to compare XGBoost with the created claim number prediction Neural Network models in the notebook \"French Motor Claims - DNN - SMOTE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collective-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = raw_df.copy().drop(columns=['IDpol'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "cleaned_df['Area'] = le.fit_transform(cleaned_df['Area'].astype(str))\n",
    "cleaned_df['VehBrand'] = le.fit_transform(cleaned_df['VehBrand'].astype(str))\n",
    "cleaned_df['VehGas'] = le.fit_transform(cleaned_df['VehGas'].astype(str))\n",
    "cleaned_df['Region'] = le.fit_transform(cleaned_df['Region'].astype(str))\n",
    "\n",
    "cleaned_df.loc[cleaned_df.ClaimNb >= 5, 'ClaimNb'] = 5\n",
    "\n",
    "# split data into X and y\n",
    "X = cleaned_df.drop(columns=['ClaimNb'])\n",
    "Y = cleaned_df['ClaimNb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romantic-malaysia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (474609,)\n",
      "Training features shape: (474609, 9)\n",
      "Validation labels shape: (203404,)\n",
      "Validation features shape: (203404, 9)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "seed = 10\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "X_train_exposure = X_train.pop('Exposure')\n",
    "X_test_exposure = X_test.pop('Exposure')\n",
    "\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation labels shape:', y_test.shape)\n",
    "print('Validation features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "maritime-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    seed=0,\n",
    "    eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formed-terrorism",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, seed=0,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cultural-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "written-heath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.05341094570411595 MSE: 0.05983166506066744 accuracy: 0.9495093508485576\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "#mpd = mean_poisson_deviance(y_test, predictions)\n",
    "\n",
    "print(\"MAE:\", mae, \"MSE:\", mse, \"accuracy:\", (y_test == y_pred).sum()/float(y_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-apartment",
   "metadata": {},
   "source": [
    "While this model has a very good performance, it still underperforms when faced against the sampled_model DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-oriental",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
